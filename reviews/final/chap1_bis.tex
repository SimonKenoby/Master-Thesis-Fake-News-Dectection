\chapter{Related Work}
\section{Introduction}
In this chapter I will detail a bit more, some related works that are worth investigating. 
\section{Supervised Learning for Fake News Detection\cite{Reis2019}}
Reis et al. use machine learning techniques on buzzfeed article related to US election. The evaluated algorithm are k-Nearest Neighbours, Na\"ive-Bayes, Random Forests, SVM with RBF kernel and XGBoost. \\

In order to feed this network, they used a lot of hand-crafted features such as 
\begin{itemize}
 \item Language Features: bag-of-words, POS tagging and others for a total of 31 different features,
 \item Lexical Features: number of unique words and their frequencies, pronouns, etc,
 \item Pyschological Features\cite{Pennebaker2001}: build using Linguistic Inquiry and Word Count which is a specific dictionary build by a text mining software,
 \item Semantic Features: Toxic score from Google's API,
 \item Engagement: Number of comments within several time interval.
\end{itemize}

Many other features were also used, based on the source and social metadata. \\

Their results is shown at \textbf{Figure \ref{fig:chap1:reis}}.

\begin{figure}[h]
 \centering
 \includegraphics[width=0.5\textwidth]{images/chap1_bis/rev1.png}
 \caption{Results by Reis et al. }
 \label{fig:chap1:reis}
\end{figure}

They also show that XGBoost is good for selecting texts that need to be hand-verified, this means that the texts classified as reliable are indeed reliable, and thus reducing the amount of texts the be checked manualy. This model is limited by the fact they do use metadata that is not always available. 

P\'erez-Rosas et al.\cite{Perez-Rosas2017} used almost the same set of features but used linear SVM as a model and worked on a different dataset.

\section{CSI: A Hybrid Deep Model for Fake News Detection}
Ruchansky et al.\cite{Ruchansky2017} used an hybrid network, merging news content features and metadata such as social engagement in a single network. To do so, they used an RNN for extracting temporal features of news content and a fully connected network in the case of social features. The results of the two networks are then concatenated and use for final classification. \\

As textual features they used doc2vec\cite{Le2014}. \\

Network's architecture is shown at \textbf{Figure \ref{fig:chap1:Ruchansky}}.

\begin{figure}[h]
 \centering
 \includegraphics[width=\textwidth]{images/chap1_bis/rev2.png}
 \caption{CSI model}
 \label{fig:chap1:Ruchansky}
\end{figure}

They did test their model on two datasets, one from Twitter and the other one from Weibo, which a Chinese equivalent of Twitter. Compared to simpler models, CSI performs better, with $6\%$ improvement over simple GRU networks (\textbf{Figure \ref{fig:chap1:Ruchansky2}}). 

\begin{figure}[h]
 \centering
 \includegraphics[width=0.5\textwidth]{images/chap1_bis/rev3.png}
 \caption{Results by Ruchansky et al. }
 \label{fig:chap1:Ruchansky2}
\end{figure}

\section{Some Like it Hoax: Automated Fake News Detection in Social Networks \cite{Tacchini2017}}
Here, Tacchini et al. focus on using social network features in order to improve the reliability of their detector. The dataset was collected using Facebook Graph API, collection pages from two main categories: scientific news and conspiracy news. They used logistic regression and harmonic algorithm\cite{NIPS2011_4396} to classify news in categories hoax and non-hoax. Harmonic Algorithm is a method that allows transferring information across users who liked some common posts. \\

For the training they used cross-validation, dividing the dataset into $80\%$ for training and $20\%$ for testing and performing 5-fold cross-validation, reaching $99\%$ of accuracy in both cases. \\

In addition they used one-page out, using posts from a single page as test data or using half of the page as training and the other half as testing. This still leads to good results, harmonic algorithm outperforming logistic regression. Results are shown at \textbf{Figures \ref{fig:chap1:tacchini}} and \textbf{\ref{fig:chap1:tacchini2}}. \\


\begin{figure}[h]
 \centering
 \includegraphics[width=0.7\textwidth]{images/chap1_bis/rev4.png}
 \caption{Results by tacchnini et al. }
 \label{fig:chap1:tacchini}
\end{figure}

\begin{figure}[h]
 \centering
 \includegraphics[width=0.7\textwidth]{images/chap1_bis/rev5.png}
 \caption{Results by tacchnini et al. }
 \label{fig:chap1:tacchini2}
\end{figure}

\section{Fake News Detection using Stacked Ensemble of Classifiers}
Thorne et al.\cite{Thorne2017} worked on \textit{Fake News Challenge} by proposing a stack of different classifiers: a multilayer perceptron with relu activation on average of word2vec for headline and tf-idf vectors for the article body, average word2vec for headlines and article body, tf-idf bigrams and unigram on article body, logistic regression with L2 regularization and concatenation of word2vec for headlines and article body with MLP and dropout. \\

Finally, a gradient boosted tree is used for the final classification. \\

\begin{figure}[h]
 \centering
 \includegraphics[width=0.7\textwidth]{images/chap1_bis/rev6.png}
 \caption{Results by Thorne et al. }
 \label{fig:chap1:thorn1}
\end{figure}

\section{Convolutional Neural Networks for Fake News Detection\cite{Yang2018}}
Yang et al. used a CNN with images contained in article in order to make the classification. They used kaggle fake news dataset\footnote{\url{https://www.kaggle.com/mrisdal/fake-news}}, in addition they scrapped real news from trusted source such as New York Times and Washington Post. \\

Their network is made of two branches: one text branch and one image branch (\textbf{Figure \ref{fig:chap1:yang1}}). The textual branch is then divided of two subbranch: textual explicit: derived information from text such as length of the news and the text latent subbranch, which is the embedding of the text, limited to 1000 words. \\
\begin{figure}[h]
 \centering
 \includegraphics[width=\textwidth]{images/chap1_bis/rev7.png}
 \caption{TI-CNN }
 \label{fig:chap1:yang1}
\end{figure}

The image branch is also made of two subbranch, one containing information such as image resolution or the number of people present on the image, the second subbranch use a CNN on the image itself. The full details of the network are at \textbf{Figure \ref{fig:chap1:yang2}}. And the results are at \textbf{Figure \ref{fig:chap1:yang3}} and show that indeed using images works better. 

\begin{figure}[h]
 \centering
 \includegraphics[width=0.7\textwidth]{images/chap1_bis/rev8.png}
 \caption{TI-CNN }
 \label{fig:chap1:yang2}
\end{figure}
\begin{figure}[h]
 \centering
 \includegraphics[width=0.7\textwidth]{images/chap1_bis/rev9.png}
 \caption{TI-CNN, results }
 \label{fig:chap1:yang3}
\end{figure}

\section{Conclusion}
We have seen in the previous sections that most of the related works focus on improving the prediction quality by adding additional features. The fact is that these features are not always available, for instance some article may not contain images. There is also the fact that using social media information is problematic because it is easy to create a new account on these media and fool the detection system. That's why I chose to focus on the article body only and see if it is possible to accurately detect fake news. 