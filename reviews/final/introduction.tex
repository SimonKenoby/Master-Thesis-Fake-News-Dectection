\chapter{Introduction} \label{section:intro}
\section{What are fake news?}
\subsection{Definition}
Fake news have quickly become a society problem, being used to propagate false or rumorus informations in order to change behaviors of peoples. Before stating to work on detecting fake news, it is needed to first understand what they are. It have been show that propagation of fake news have had a non negligable influence of 2016 US presidential elections\cite{Allcott2017}. A few facts on fake news in the United States: 

\begin{itemize}
	\item $62\%$ of US citizen get there news for social medias\cite{gottfried2016news}
	\item Fake news had more share on facebook than mainstream news\cite{silverman2016teens}.
\end{itemize}

Fake news have also been used in order to influence the referendum in the United Kingdom for the "Brexit". \\

In this paper I experiment the possibility to detect fake news based only on textual information by applying traditional machine learning techniques\cite{Fan2008LIBLINEARAL,Robertson2004,zhang_optimality_nodate} as well as bidirectional-LSTM\cite{Hochreiter1997LongSM} and attention mechanism\cite{zhou-etal-2016-attention} on two different dataset that contains different kinds of news.

%TODO: Define fake news
%TODO: Expliquer les differentes méthodes de détection de fake news dans le paper Fake News Detection on Social Media: A Data Mining Perspective 1708.01967v3.pdf
There are two aspects of fake news detection that need to be taken into account according to Shu et al\cite{shu2017fake}. The first is characterization or what are fake news and the second is detection. In order to build detection models, it is need to start by charaterization, indeed, it is need to understand what are fake news before trying to detect them. \\

Fake news definition is made of two part: authenticity and intent. Authenticity means that fake news content fale information that can be verified as such, which means that concpiracy theory is not included in fake news as there are difficult to be proven true or false in most cases. The second part, intent, means that the false information have been written with the goal of missleading the reader. 


\begin{figure}
	\centering
	\includegraphics[width=0.8\textwidth]{images/introduction/characterization.png}
	\caption{Fake news on social media: from characterization to detection.\cite{shu2017fake}}
	\label{fig:intro:characterization}
\end{figure}

\subsection{Fake News Characterization}
\newtheorem{def:fake_news}{Definition}

\begin{def:fake_news}
Fake news is a news article that is intentionally and verifiably false
\end{def:fake_news}

The part of the definition introducing the intent of missleading the reader automaticaly discard satire news medias, that is why this works will focus on the first part, the fact that the piece of information is verifiably false or true. Indded, even if satire news medias does not have the intent to misslead the readers, not all of them have the ability of making criticisme and not taking it to the first degree. On the other hand, in the case of political media, even if it clearly try to influence the consumer, verifying the authenticity of there claims is usualy harder as, in most of the cases, openly lies. 

\section{Feature Extraction} \label{intro:feature_extract}
\subsection{News Content Features}
Now that fake news have been defined and the target have been set, it is needed to analize what features can be used in order to classify fake news. Starting by looking at news content, it can be seen that it is made of four principal raw components: 
\begin{itemize}
	\item \textbf{Source}: Where does the news come from, who wrote it, is this source reliable or not.
	\item \textbf{Headline}: Short summary of the news content that try to attract the reader.
	\item \textbf{Body Text}: The actual text content of the news.
	\item \textbf{Image/Video}: Usualy, textual information is agremented with visual information such as images, videos or audio.  
\end{itemize}

Features will be extracted from these four basic components, with the mains features being linguistic-based and visual-based. 
As explained before, fake news are used to influence the consumer, and in order to do that, they often use a specific language in order to attract the readers. On the other hand, non fake news will mostly stick to a different language register, being more formal. This are linguistic-based features, to which can be added lexical features such as total number of words, frequency of large words or unique words. \\

The second features that need to be taken into account are visual features. Indeed, modified images are often used to add more weight to the textual information. For example, the \textbf{Figure \ref{fig:intro:deforestation}} is supposed to show the progress of deforestation, but the two images are acutaly from the same original one, and in addition the WWF logo make it looks like to be from a trusted source. 

\begin{figure*}
	\centering
	\includegraphics[width=0.8\textwidth]{images/introduction/fake-news-photos-viral-photoshop-8-5c6fe61f88240__700}
	\caption{The two images provided to show deforestation between two date are from the same image taken at the same time.}
	\label{fig:intro:deforestation}
\end{figure*}

\subsection{Social Context Features}
In the context of news sharing on social medias, multiples aspect can be taken into account, such as user aspect, post aspect and group aspect. For instance, it is possible to analyize the behavior of specific users and use their metadata in order to find if a user is at risk of trusting or sharing false information. For instance, those metadata can be its center of intereset, its number of followers, or anything that relates to it. \\

Post-based aspect is in a sense similar to user based: it can use post metadata in order to provide usefull informations, but in addition to metadata, the actual content can be used. It is also possible to extract features from the content using latent Dirichlet allocation (LDA)\cite{blei2003latent}.

\section{News Content Models} \label{intro:models}
\subsection{Knowledge-based models}
Now that the differents kinds of features available for the news have been defined, it is possible to start to explain what kind of models can be built using these features. The first models that relates to the news content is based on knowledge: the goal of this model is to check the truthfulness of the news content and can be acheived in tree differents way (or a mixture of them):

\begin{itemize}
	\item \textbf{Expert-oriented}: relies on expert, such as journalist or scientist, to asses the news content.
	\item \textbf{Crowdsourcing-oriented}: relies on the wisdom of crowd that says that if a suficiently large amount of persons says that something is false or true then it should be.
	\item \textbf{Computational-oriented}: relies on automatic fact checking, that could be based on external resources shuch as DBpedia.
\end{itemize}
These methods all have pros and cons, hiring expert might be constly, and expert are limited in number and might not be able to treat all the news that are produced. In the case of crowdsourcing it can easily be fooled if enought bad annotators breaks the system and automatic fact checking might not have the necessary accuracy.

\subsection{Style-based model}
As explained earlier, fake news usualy tries to influence consumier behavior, and thus generaly use a specific style in order to play on the emotion. These methods are called deception-oriented stylometric methods. \\

The second method is called objectivity-oriented approaches and tries to capture the objectivity of the texts or headlines. These kind of style is mostly used by partisan article or yellow-journalism, that is, website that relies on eye-catching headline without reporting any useful information. An example of these kind of headline could be:
	\begin{quote}You will never beleive what he did !!!!!!\end{quote} 
This kind of headline plays on the curiosity of the reader that would click to read the news.

\section{Social Context Models}
The last features that have not been used yet are social media features. There are two approaches to use these features: stance-based and propagation-based. 

\paragraph{Stence-based} approaches use implicit or explicit representation. For instance, explicit representation might be positive or negative votes on social medias. Implicit representation need to be extracted from the post itself. 

\paragraph{Propagation-based} approaches use features related to sharing such as the number of retweet on twitter. 

\section{Related Works}
\subsection{Fake news detection}
Current research focus mostly on using socials features and speaker informations in order to improve the quality of classifications.\\

Ruchansky et al.\cite{Ruchansky2017} proposed an hybrid deep model for fake news detection making use of multiple kind a features such as temporal engagement between n users and m news-articles over time and produce a label for fake news categorisation but as well a score for suspicious users.\\

Long et al. \cite{Long2017} proposed to apply attention mechanism to the speaker profile in an hybrid way with an LSTM on the textual information. \\

Tacchini et al.\cite{Tacchini2017} proposed a method based on social network informations such as likes and users in order to find hoax information.\\

Thorne et al.\cite{Thorne2017} proposed a stacked ensemble classifier in order to adress a subproblem of fake news dectection which is stance classification. It is the fact of finding if an articile agree, disagree or simply discus a fact. \\

Granik and Mesyura\cite{Granik2017} used Naïve-Bayes classifier in order to classify news from buzzfeed dataset.\\

In addition to text and social features, Yang et al.\cite{Yang2018} used visual features such as images with a convolutional neural network. \\

Wang et al.\cite{Wang2018} also used visual features for classifying fake news but uses adversarial neural network to do so. 
\subsection{State of the Art Text classification}
There are two mains categories of state of the art that are interesting for this work: previous work on fake news detection and on general text classification. Works on fake news detection is almost inexistant and mainly focus on 2016 US presidential elections or does not uses the sames features. That is, when this work focus on automatic features extraction using machine learning and deep learning, other works make use of hand crafted features\cite{Reis2019,Perez-Rosas2017} such as psycholinguistic features\cite{Pennebaker2001} which is not the goal here. \\

When it comes to state of the art for text classifiction, it includes Long short-term memory (LSTM)\cite{Hochreiter1997LongSM}, Attention Mechanism\cite{Vaswani2017AttentionIA}, IndRNN\cite{Li2018}, Attention-Based Bidirection LSTM\cite{zhou-etal-2016-attention}, Hierarchical Attention Networks for Text Classification\cite{yang_hierarchical_2016}, Adversarial Training Methods For Supervised Text Classification\cite{miyato_adversarial_2016}, Convolutional Neural Networks for Sentence Classification\cite{kim_convolutional_2014} and RMDL: Random Multimodel Deep Learning for Classification\cite{kowsari_rmdl:_2018}. All of these models have comparable performances. 
\section{Conclusion}
As it have been shown in \textbf{Section \ref{intro:feature_extract}} and \textbf{Section \ref{intro:models}} mutliples approaches can be used in order to extract features and use them in models. This works focus on textual news content features. Indeed, other features related to social medias are difficult to aquire. For example, users information are difficult to obtain on Facebook, as well as post information. In addition, the different datasets that have been presented at \textbf{Section \ref{intro:dataset}} does not provides any other information than textual ones. \\

Looking at \textbf{Figure \ref{fig:intro:features}} it can be seen that the main focus will be made on unsupervised and supervised learning models using textual news content. It should be noted that machine learning models usualy comes with a trade-off between precision and recall and thus that a model which is very good at detected fake news might have a high false positive rate as opposite to a model with a low false positive rate which might not be good at detecting them. This cause ethical questions such as automatic censorship that will not be discused here. 

\begin{figure*}
	\centering
	\includegraphics[width=0.8\textwidth]{images/introduction/features}
	\caption{Differents approaches to fake news detection.}
	\label{fig:intro:features}
\end{figure*}