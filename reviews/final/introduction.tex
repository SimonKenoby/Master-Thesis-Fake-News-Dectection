\chapter{Introduction} \label{section:intro}
\section{What are fake news?}
\subsection{Definition}
Fake news has quickly become a society problem, being used to propagate false or rumour information in order to change people’s behaviour. It has been shown that propagation of fake news has had a non-negligible influence of 2016 US presidential elections\cite{Allcott2017}. A few facts on fake news in the United States: 
\begin{itemize}
 \item $62\%$ of US citizens get their news for social medias\cite{gottfried2016news}
 \item Fake news had more share on Facebook than mainstream news\cite{silverman2016teens}.
\end{itemize}
Fake news has also been used in order to influence the referendum in the United Kingdom for the "Brexit". \\

In this paper I experiment the possibility to detect fake news based only on textual information by applying traditional machine learning techniques\cite{Fan2008LIBLINEARAL,Robertson2004,zhang_optimality_nodate} as well as bidirectional-LSTM\cite{Hochreiter1997LongSM} and attention mechanism\cite{zhou-etal-2016-attention} on two different datasets that contain different kinds of news.\\
%TODO: Define fake news
%TODO: Expliquer les differentes mÃ©thodes de dÃ©tection de fake news dans le paper Fake News Detection on Social Media: A Data Mining Perspective 1708.01967v3.pdf
In order to work on fake news detection, it is important to understand what is fake news and how they are characterized. The following is based on \textit{Fake News Detection on Social Media: A Data Mining Perspective}\cite{shu2017fake}.\\

The first is characterization or what is fake news and the second is detection. In order to build detection models, it is need to start by characterization, indeed, it is need to understand what is fake news before trying to detect them. \\

Fake news definition is made of two parts: authenticity and intent. Authenticity means that fake news content false information that can be verified as such, which means that conspiracy theory is not included in fake news as there are difficult to be proven true or false in most cases. The second part, intent, means that the false information has been written with the goal of misleading the reader. 

\begin{figure}
 \centering
 \includegraphics[width=0.8\textwidth]{images/introduction/characterization.png}
 \caption{Fake news on social media: from characterization to detection.\cite{shu2017fake}}
 \label{fig:intro:characterization}
\end{figure}
\subsection{Fake News Characterization}
\newtheorem{def:fake_news}{Definition}
\begin{def:fake_news}
Fake news is a news article that is intentionally and verifiable false
\end{def:fake_news}
The part of the definition introducing the intent of misleading the reader automatically discard satire news media, that is why this work will focus on the first part, the fact that the piece of information is verifiable false or true. Indeed, even if satire news media does not have the intent to mislead the readers, not all of them have the ability of making criticism and not taking it to the first degree. On the other hand, in the case of political media, even if it clearly tries to influence the consumer, verifying the authenticity of there claims is usually harder as, in most of the cases, openly lies. 
\section{Feature Extraction} \label{intro:feature_extract}
\subsection{News Content Features}
Now that fake news has been defined and the target has been set, it is needed to analyse what features can be used in order to classify fake news. Starting by looking at news content, it can be seen that it is made of four principal raw components: 
\begin{itemize}
 \item \textbf{Source}: Where does the news come from, who wrote it, is this source reliable or not.
 \item \textbf{Headline}: Short summary of the news content that try to attract the reader.
 \item \textbf{Body Text}: The actual text content of the news.
 \item \textbf{Image/Video}: Usualy, textual information is agremented with visual information such as images, videos or audio.  
\end{itemize}
Features will be extracted from these four basic components, with the mains features being linguistic-based and visual-based. 
As explained before, fake news is used to influence the consumer, and in order to do that, they often use a specific language in order to attract the readers. On the other hand, non-fake news will mostly stick to a different language register, being more formal. This is linguistic-based features, to which can be added lexical features such as the total number of words, frequency of large words or unique words. \\

The second features that need to be taken into account are visual features. Indeed, modified images are often used to add more weight to the textual information. For example, the \textbf{Figure \ref{fig:intro:deforestation}} is supposed to show the progress of deforestation, but the two images are actually from the same original one, and in addition the WWF logo makes it look like to be from a trusted source. 
\begin{figure*}
 \centering
 \includegraphics[width=0.8\textwidth]{images/introduction/fake-news-photos-viral-photoshop-8-5c6fe61f88240__700}
 \caption{The two images provided to show deforestation between two dates are from the same image taken at the same time. \cite{WWF2019}}
 \label{fig:intro:deforestation}
\end{figure*}
\subsection{Social Context Features}
In the context of news sharing on social media, multiple aspect can be taken into account, such as user aspect, post aspect and group aspect. For instance, it is possible to analyse the behaviour of specific users and use their metadata in order to find if a user is at risk of trusting or sharing false information. For instance, this metadata can be its centre of interest, its number of followers, or anything that relates to it. \\

Post-based aspect is in a sense similar to users based: it can use post metadata in order to provide useful information, but in addition to metadata, the actual content can be used. It is also possible to extract features from the content using latent Dirichlet allocation (LDA)\cite{blei2003latent}.
\section{News Content Models} \label{intro:models}
\subsection{Knowledge-based models}
Now that the different kinds of features available for the news have been defined, it is possible to start to explain what kinds of models can be built using these features. The first model that relates to the news content is based on knowledge: the goal of this model is to check the truthfulness of the news content and can be achieved in three different ways (or a mixture of them):
\begin{itemize}
 \item \textbf{Expert-oriented}: relies on experts, such as journalists or scientists, to assess the news content.
 \item \textbf{Crowdsourcing-oriented}: relies on the wisdom of crowd that says that if a sufficiently large number of persons say that something is false or true then it should be.
 \item \textbf{Computational-oriented}: relies on automatic fact checking, that could be based on external resources such as DBpedia.
\end{itemize}
These methods all have pros and cons, hiring experts might be costly, and expert are limited in number and might not be able to treat all the news that is produced. In the case of crowdsourcing, it can easily be fooled if enough bad annotators break the system and automatic fact checking might not have the necessary accuracy.
\subsection{Style-Based Model}
As explained earlier, fake news usually tries to influence consumer behaviour, and thus generally use a specific style in order to play on the emotion. These methods are called deception-oriented stylometric methods. \\

The second method is called objectivity-oriented approaches and tries to capture the objectivity of the texts or headlines. These kind of style is mostly used by partisan articles or yellow journalism, that is, websites that rely on eye-catching headlines without reporting any useful information. An example of these kind of headline could be
 \begin{quote}You will never believe what he did !!!!!!\end{quote} 
This kind of headline plays on the curiosity of the reader that would click to read the news.
\section{Social Context Models}
The last features that have not been used yet are social media features. There are two approaches to use these features: stance-based and propagation-based. 
\paragraph{Stance-based} approaches use implicit or explicit representation. For instance, explicit representation might be positive or negative votes on social media. Implicit representation needs to be extracted from the post itself. 
\paragraph{Propagation-based} approaches use features related to sharing such as the number of retweet on twitter. 
\section{Related Works}
\subsection{Fake news detection}
There are two main categories of state of the art that are interesting for this work: previous work on fake news detection and on general text classification. Works on fake news detection is almost inexistent and mainly focus in 2016 US presidential elections or does not use the same features. That is, when this work focus on automatic features extraction using machine learning and deep learning, other works make use of hand-crafted features\cite{Reis2019,Perez-Rosas2017} such as psycholinguistic features\cite{Pennebaker2001} which are not the goal here. \\

Current research focus mostly on using social features and speaker information in order to improve the quality of classifications.\\

Ruchansky et al.\cite{Ruchansky2017} proposed a hybrid deep model for fake news detection making use of multiple kinds of feature such as temporal engagement between n users and m news articles over time and produce a label for fake news categorization but as well a score for suspicious users.\\

Tacchini et al.\cite{Tacchini2017} proposed a method based on social network information such as likes and users in order to find hoax information.\\

Thorne et al.\cite{Thorne2017} proposed a stacked ensemble classifier in order to address a subproblem of fake news detection which is stance classification. It is the fact of finding if an article agree, disagree or simply discus a fact. \\

Granik and Mesyura\cite{Granik2017} used Na\"ive-Bayes classifier in order to classify news from buzzfeed datasets.\\

In addition to texts and social features, Yang et al.\cite{Yang2018} used visual features such as images with a convolutional neural network. \\

Wang et al.\cite{Wang2018} also used visual features for classifying fake news but uses adversarial neural networks to do so. 
\subsection{State of the Art Text classification}
When it comes to state of the art for text classification, it includes Long short-term memory (LSTM)\cite{Hochreiter1997LongSM}, Attention Mechanism\cite{Vaswani2017AttentionIA}, IndRNN\cite{Li2018}, Attention-Based Bidirection LSTM\cite{zhou-etal-2016-attention}, Hierarchical Attention Networks for Text Classification\cite{yang_hierarchical_2016}, Adversarial Training Methods For Supervised Text Classification\cite{miyato_adversarial_2016}, Convolutional Neural Networks for Sentence Classification\cite{kim_convolutional_2014} and RMDL: Random Multimodel Deep Learning for Classification\cite{kowsari_rmdl:_2018}. All of these models have comparable performances. 
\section{Conclusion}
As it has been shown in \textbf{Section \ref{intro:feature_extract}} and \textbf{Section \ref{intro:models}} multiple approaches can be used in order to extract features and use them in models. This works focus on textual news content features. Indeed, other features related to social media are difficult to acquire. For example, users’ information is difficult to obtain on Facebook, as well as post information. In addition, the different datasets that have been presented at \textbf{Section \ref{intro:dataset}} does not provide any other information than textual ones. \\

Looking at \textbf{Figure \ref{fig:intro:features}} it can be seen that the main focus will be made on unsupervised and supervised learning models using textual news content. It should be noted that machine learning models usually comes with a trade-off between precision and recall and thus that a model which is very good at detected fake news might have a high false positive rate as opposite to a model with a low false positive rate which might not be good at detecting them. This cause ethical questions such as automatic censorship that will not be discussed here. 
\begin{figure*}
 \centering
 \includegraphics[width=0.8\textwidth]{images/introduction/features}
 \caption{Different approaches to fake news detection.}
 \label{fig:intro:features}
\end{figure*}