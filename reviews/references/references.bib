% Encoding: UTF-8

@Article{Zhou2015,
  author      = {Chunting Zhou and Chonglin Sun and Zhiyuan Liu and Francis C. M. Lau},
  title       = {A C-LSTM Neural Network for Text Classification},
  abstract    = {Neural network models have been demonstrated to be capable of achieving remarkable performance in sentence and document modeling. Convolutional neural network (CNN) and recurrent neural network (RNN) are two mainstream architectures for such modeling tasks, which adopt totally different ways of understanding natural languages. In this work, we combine the strengths of both architectures and propose a novel and unified model called C-LSTM for sentence representation and text classification. C-LSTM utilizes CNN to extract a sequence of higher-level phrase representations, and are fed into a long short-term memory recurrent neural network (LSTM) to obtain the sentence representation. C-LSTM is able to capture both local features of phrases as well as global and temporal sentence semantics. We evaluate the proposed architecture on sentiment classification and question classification tasks. The experimental results show that the C-LSTM outperforms both CNN and LSTM and can achieve excellent performance on these tasks.},
  date        = {2015-11-27},
  eprint      = {1511.08630v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1511.08630v2:PDF},
  keywords    = {cs.CL},
}

@Article{Chawla2011,
  author       = {N. V. Chawla and K. W. Bowyer and L. O. Hall and W. P. Kegelmeyer},
  title        = {SMOTE: Synthetic Minority Over-sampling Technique},
  abstract     = {An approach to the construction of classifiers from imbalanced datasets is described. A dataset is imbalanced if the classification categories are not approximately equally represented. Often real-world data sets are predominately composed of "normal" examples with only a small percentage of "abnormal" or "interesting" examples. It is also the case that the cost of misclassifying an abnormal (interesting) example as a normal example is often much higher than the cost of the reverse error. Under-sampling of the majority (normal) class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class. This paper shows that a combination of our method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples. Experiments are performed using C4.5, Ripper and a Naive Bayes classifier. The method is evaluated using the area under the Receiver Operating Characteristic curve (AUC) and the ROC convex hull strategy.},
  date         = {2011-06-09},
  doi          = {10.1613/jair.953},
  eprint       = {1106.1813v1},
  eprintclass  = {cs.AI},
  eprinttype   = {arXiv},
  file         = {online:http\://arxiv.org/pdf/1106.1813v1:PDF},
  journaltitle = {Journal Of Artificial Intelligence Research, Volume 16, pages 321-357, 2002},
  keywords     = {cs.AI},
}

@Article{Rao2016,
  author      = {Adithya Rao and Nemanja Spasojevic},
  title       = {Actionable and Political Text Classification using Word Embeddings and LSTM},
  abstract    = {In this work, we apply word embeddings and neural networks with Long Short-Term Memory (LSTM) to text classification problems, where the classification criteria are decided by the context of the application. We examine two applications in particular. The first is that of Actionability, where we build models to classify social media messages from customers of service providers as Actionable or Non-Actionable. We build models for over 30 different languages for actionability, and most of the models achieve accuracy around 85%, with some reaching over 90% accuracy. We also show that using LSTM neural networks with word embeddings vastly outperform traditional techniques. Second, we explore classification of messages with respect to political leaning, where social media messages are classified as Democratic or Republican. The model is able to classify messages with a high accuracy of 87.57%. As part of our experiments, we vary different hyperparameters of the neural networks, and report the effect of such variation on the accuracy. These actionability models have been deployed to production and help company agents provide customer support by prioritizing which messages to respond to. The model for political leaning has been opened and made available for wider use.},
  date        = {2016-07-08},
  eprint      = {1607.02501v2},
  eprintclass = {cs.CL},
  eprinttype  = {arXiv},
  file        = {online:http\://arxiv.org/pdf/1607.02501v2:PDF},
  keywords    = {cs.CL, cs.IR, 68T50, 92B20},
}

@Comment{jabref-meta: databaseType:bibtex;}
